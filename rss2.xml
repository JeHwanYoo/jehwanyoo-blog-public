<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>JeHwan PL Note</title>
    <link>https://jehwanyoo.net/</link>
    
    <atom:link href="https://jehwanyoo.net/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>프로그래밍 노트, 팁, 강의등을 게시하는 블로그입니다.</description>
    <pubDate>Sun, 06 Mar 2022 08:13:25 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>머신 러닝을 해보자 6장 - 텐서플로우 기초</title>
      <link>https://jehwanyoo.net/2022/03/06/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%95%B4%EB%B3%B4%EC%9E%90-6%EC%9E%A5-%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%EA%B8%B0%EC%B4%88/</link>
      <guid>https://jehwanyoo.net/2022/03/06/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%95%B4%EB%B3%B4%EC%9E%90-6%EC%9E%A5-%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%EA%B8%B0%EC%B4%88/</guid>
      <pubDate>Sun, 06 Mar 2022 08:00:27 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;텐서란-Tensor&quot;&gt;&lt;a href=&quot;#텐서란-Tensor&quot; class=&quot;headerlink&quot; title=&quot;텐서란? (Tensor)&quot;&gt;&lt;/a&gt;텐서란? (Tensor)&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;선형대수학에서 사용하는 수학적 대상을 텐서(Ten</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="텐서란-Tensor"><a href="#텐서란-Tensor" class="headerlink" title="텐서란? (Tensor)"></a>텐서란? (Tensor)</h2><hr><p>선형대수학에서 사용하는 수학적 대상을 텐서(Tensor)라고 한다.</p><p>스칼라, 벡터, 행렬, n-차원 배열등을 일반화(Generalization)한 개념이다.</p><p>19세기 미분 기하학에서 처음 도입하였으며, 물리학, 공학을 비롯한 다양한 학문에서 이용된다.</p><h2 id="랭크-Rank"><a href="#랭크-Rank" class="headerlink" title="랭크 (Rank)"></a>랭크 (Rank)</h2><hr><p>텐서에는 Rank라는 개념이 존재하며 텐서의 차원 수를 의미한다.</p><p>Rank를 Order라고도 한다.</p><p>낮은 Rank부터 연산이 정의되어 더 높은 Rank로 확장되기 때문이다.</p><table><thead><tr><th align="center">Rank</th><th align="center">데이터 타입</th></tr></thead><tbody><tr><td align="center">0</td><td align="center">스칼라 (0-order-tensor)</td></tr><tr><td align="center">1</td><td align="center">벡터 (1-order-tensor)</td></tr><tr><td align="center">2</td><td align="center">행렬 (2-order-tensor)</td></tr><tr><td align="center">3</td><td align="center">(3-order-tensor)</td></tr><tr><td align="center">…</td><td align="center">…</td></tr><tr><td align="center">n</td><td align="center">(n-order-tensor)</td></tr></tbody></table><h2 id="Tensor-예제"><a href="#Tensor-예제" class="headerlink" title="Tensor 예제"></a>Tensor 예제</h2><hr><p>Tensor를 실험하기 위해 머신 러닝 프레임워크인 Tensorflow를 사용해보자.</p><p>아래는 Tensorflow + Keras로 Linear Function을 표현하였다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense </span><br><span class="line"></span><br><span class="line">x = tf.constant([[<span class="number">10.</span>, <span class="number">20.</span>], [<span class="number">30.</span>, <span class="number">40.</span>], [<span class="number">50.</span>, <span class="number">60.</span>]])</span><br><span class="line"></span><br><span class="line">dense = Dense(units = <span class="number">1</span>) <span class="comment"># Linear Function</span></span><br><span class="line"></span><br><span class="line">y = dense(x) <span class="comment"># Initialize W &amp; Feed Forward</span></span><br><span class="line">W, b = dense.get_weights()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;y = x﹒<span class="subst">&#123;W&#125;</span> + <span class="subst">&#123;b&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;x.shape: <span class="subst">&#123;x.shape&#125;</span> W.shape: <span class="subst">&#123;W.shape&#125;</span> B.shape: <span class="subst">&#123;b.shape&#125;</span>&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">y = x﹒[[0.08496201]</span><br><span class="line"> [0.19183493]] + [0.]</span><br><span class="line">x.shape: (3, 2) W.shape: (2, 1) B.shape: (1,)</span><br><span class="line">tf.Tensor(</span><br><span class="line">[[ 4.6863184]</span><br><span class="line"> [10.222258 ]</span><br><span class="line"> [15.758196 ]], shape=(3, 1), dtype=float32)</span><br></pre></td></tr></table></figure><img src="https://i.ibb.co/x6ZrrWg/6-2022-002.jpg" alt="https://i.ibb.co/x6ZrrWg/6-2022-002.jpg" width="600"><p>머신 러닝에 등장하는 x(입력), W(가중치), b(바이어스) 모두 행렬 또는 벡터의 연산이며,</p><p>다시 말해 텐서의 연산이라고 볼 수 있다.</p><h2 id="상수-텐서-선언"><a href="#상수-텐서-선언" class="headerlink" title="상수 텐서 선언"></a>상수 텐서 선언</h2><hr><p>상수 텐서는 <code>tf.constant</code> 함수로 선언할 수 있다.</p><p>상수 텐서는 연산을 진행하는 동안 ‘텐서 객체의 값’이 변하지 않는다.</p><blockquote><p>a = tf.constant(10)을 생각해보자.</p><p>여기서 바뀌지 않는 것은 tf.Tensor 객체이다. a는 지역 변수이므로 바뀔 수 있다.</p><p>a가 tf.Tensor가 되는게 아니라 a는 레퍼런스 변수로써 tf.Tensor를 가리키고 있는 것이다. (포인터 개념)</p><p>좀 더 자세히 알고 싶다면 포인터를 직접 사용하는 C언어나 C++ 언어를 접해보길 권장한다.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># RANK-0</span></span><br><span class="line">a = tf.constant(<span class="number">10.</span>)</span><br><span class="line">b = tf.constant(-<span class="number">5.</span>)</span><br><span class="line">c = a + b</span><br><span class="line">d = a * b</span><br><span class="line">e = a - b</span><br><span class="line">f = a / b</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;rank-0&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;a&#x27;</span>, a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;c&#x27;</span>, c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;d&#x27;</span>, d)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;e&#x27;</span>, e)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;f&#x27;</span>, f)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># RANK-1</span></span><br><span class="line">a = tf.constant([<span class="number">5.</span>, -<span class="number">4.</span>])</span><br><span class="line">b = tf.constant([-<span class="number">2.</span>, -<span class="number">3.</span>])</span><br><span class="line">c = a + b</span><br><span class="line">d = a * b</span><br><span class="line">e = a - b</span><br><span class="line">f = a / b</span><br><span class="line">g = tf.tensordot(a, b, axes=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;rank-1&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;a&#x27;</span>, a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;c&#x27;</span>, c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;d&#x27;</span>, d)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;e&#x27;</span>, e)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;f&#x27;</span>, f)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;g&#x27;</span>, g)</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"></span><br><span class="line"><span class="comment"># RANK-2</span></span><br><span class="line">a = tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>], [<span class="number">3.</span>, <span class="number">4.</span>]])</span><br><span class="line">b = tf.constant([[<span class="number">5.</span>, <span class="number">6.</span>], [<span class="number">7.</span>, <span class="number">8.</span>]])</span><br><span class="line">c = a + b</span><br><span class="line">d = a * b <span class="comment"># 아다마르 프로덕트</span></span><br><span class="line">e = a - b</span><br><span class="line">f = a / b</span><br><span class="line">g = tf.linalg.matmul(a, b) <span class="comment"># 도트 프로덕트</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;rank-2&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;a&#x27;</span>, a)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;c&#x27;</span>, c)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;d&#x27;</span>, d)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;e&#x27;</span>, e)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;f&#x27;</span>, f)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;g&#x27;</span>, g)</span><br><span class="line"><span class="built_in">print</span>()</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">rank-0</span><br><span class="line">a tf.Tensor(10.0, shape=(), dtype=float32)</span><br><span class="line">b tf.Tensor(-5.0, shape=(), dtype=float32)</span><br><span class="line">c tf.Tensor(5.0, shape=(), dtype=float32)</span><br><span class="line">d tf.Tensor(-50.0, shape=(), dtype=float32)</span><br><span class="line">e tf.Tensor(15.0, shape=(), dtype=float32)</span><br><span class="line">f tf.Tensor(-2.0, shape=(), dtype=float32)</span><br><span class="line"></span><br><span class="line">rank-1</span><br><span class="line">a tf.Tensor([ 5. -4.], shape=(2,), dtype=float32)</span><br><span class="line">b tf.Tensor([-2. -3.], shape=(2,), dtype=float32)</span><br><span class="line">c tf.Tensor([ 3. -7.], shape=(2,), dtype=float32)</span><br><span class="line">d tf.Tensor([-10.  12.], shape=(2,), dtype=float32)</span><br><span class="line">e tf.Tensor([ 7. -1.], shape=(2,), dtype=float32)</span><br><span class="line">f tf.Tensor([-2.5        1.3333334], shape=(2,), dtype=float32)</span><br><span class="line">g tf.Tensor(2.0, shape=(), dtype=float32)</span><br><span class="line"></span><br><span class="line">rank-2</span><br><span class="line">a tf.Tensor(</span><br><span class="line">[[1. 2.]</span><br><span class="line"> [3. 4.]], shape=(2, 2), dtype=float32)</span><br><span class="line">b tf.Tensor(</span><br><span class="line">[[5. 6.]</span><br><span class="line"> [7. 8.]], shape=(2, 2), dtype=float32)</span><br><span class="line">c tf.Tensor(</span><br><span class="line">[[ 6.  8.]</span><br><span class="line"> [10. 12.]], shape=(2, 2), dtype=float32)</span><br><span class="line">d tf.Tensor(</span><br><span class="line">[[ 5. 12.]</span><br><span class="line"> [21. 32.]], shape=(2, 2), dtype=float32)</span><br><span class="line">e tf.Tensor(</span><br><span class="line">[[-4. -4.]</span><br><span class="line"> [-4. -4.]], shape=(2, 2), dtype=float32)</span><br><span class="line">f tf.Tensor(</span><br><span class="line">[[0.2        0.33333334]</span><br><span class="line"> [0.42857143 0.5       ]], shape=(2, 2), dtype=float32)</span><br><span class="line">g tf.Tensor(</span><br><span class="line">[[19. 22.]</span><br><span class="line"> [43. 50.]], shape=(2, 2), dtype=float32)</span><br></pre></td></tr></table></figure><p>Tensorflow의 Tensor는 numpy 호환 배열과, <code>.shape</code>, <code>.dtype</code>을 가지고 있다.</p><p>Tensorflow 2.0부터 Session 방식을 사용하지 않기 떄문에, Tensor를 평가하기 위해 <code>.eval()</code> 대신 <code>.numpy()</code>를 사용한다.</p><h2 id="초기화-함수"><a href="#초기화-함수" class="headerlink" title="초기화 함수"></a>초기화 함수</h2><hr><p>초기화 함수를 이용하여 영백터, 영행렬, 단위행렬, 대각행렬, 난수텐서 등을 생성할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.zeros(<span class="number">2</span>) <span class="comment"># 2d O-vector</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;a&#x27;</span>, a)</span><br><span class="line"></span><br><span class="line">b = tf.ones((<span class="number">4</span>, <span class="number">4</span>)) <span class="comment"># 4x4 Matrix</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b)</span><br><span class="line"></span><br><span class="line">c = tf.eye(<span class="number">4</span>) <span class="comment"># 4x4 Identify Matrix</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;c&#x27;</span>, c)</span><br><span class="line"></span><br><span class="line">d = tf.fill((<span class="number">3</span>, <span class="number">2</span>), value=<span class="number">5.</span>) <span class="comment"># 3x2 Matrix</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;d&#x27;</span>, d)</span><br><span class="line"></span><br><span class="line">e = tf.linalg.diag(tf.<span class="built_in">range</span>(<span class="number">1</span>, <span class="number">5</span>, <span class="number">1</span>)) <span class="comment"># Diagonal Matrix</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;e&#x27;</span>, e)</span><br><span class="line"></span><br><span class="line">f = tf.random.normal((<span class="number">2</span>, <span class="number">2</span>), mean=<span class="number">0</span>, stddev=<span class="number">1</span>) <span class="comment"># Normal Distribution</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;f&#x27;</span>, f)</span><br><span class="line"></span><br><span class="line">g = tf.random.uniform((<span class="number">2</span>, <span class="number">2</span>), minval=-<span class="number">2</span>, maxval=<span class="number">2</span>) <span class="comment"># Uniform Distribution</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;g&#x27;</span>, g)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">a tf.Tensor([0. 0.], shape=(2,), dtype=float32)</span><br><span class="line">b tf.Tensor(</span><br><span class="line">[[1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1.]</span><br><span class="line"> [1. 1. 1. 1.]], shape=(4, 4), dtype=float32)</span><br><span class="line">c tf.Tensor(</span><br><span class="line">[[1. 0. 0. 0.]</span><br><span class="line"> [0. 1. 0. 0.]</span><br><span class="line"> [0. 0. 1. 0.]</span><br><span class="line"> [0. 0. 0. 1.]], shape=(4, 4), dtype=float32)</span><br><span class="line">d tf.Tensor(</span><br><span class="line">[[5. 5.]</span><br><span class="line"> [5. 5.]</span><br><span class="line"> [5. 5.]], shape=(3, 2), dtype=float32)</span><br><span class="line">e tf.Tensor(</span><br><span class="line">[[1 0 0 0]</span><br><span class="line"> [0 2 0 0]</span><br><span class="line"> [0 0 3 0]</span><br><span class="line"> [0 0 0 4]], shape=(4, 4), dtype=int32)</span><br><span class="line">f tf.Tensor(</span><br><span class="line">[[ 0.26831564 -1.0274279 ]</span><br><span class="line"> [-0.26385054 -2.047377  ]], shape=(2, 2), dtype=float32)</span><br><span class="line">g tf.Tensor(</span><br><span class="line">[[-1.0781832   1.899333  ]</span><br><span class="line"> [-0.43762493 -1.9079366 ]], shape=(2, 2), dtype=float32)</span><br></pre></td></tr></table></figure><h2 id="텐서-형상-조작"><a href="#텐서-형상-조작" class="headerlink" title="텐서 형상 조작"></a>텐서 형상 조작</h2><hr><p><code>tf.reshape</code> 함수를 이용하면 다른 형상의 텐서로 바꿀수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">3</span>, <span class="number">4</span>], [<span class="number">5</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;a: <span class="subst">&#123;a&#125;</span>, a.shape: <span class="subst">&#123;a.shape&#125;</span>&#x27;</span>)</span><br><span class="line">b = tf.reshape(a, (<span class="number">6</span>, )) <span class="comment"># flatten</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;b: <span class="subst">&#123;b&#125;</span>, b.shape: <span class="subst">&#123;b.shape&#125;</span>&#x27;</span>)</span><br><span class="line">c = tf.reshape(b, (<span class="number">2</span>, <span class="number">3</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&#x27;c: <span class="subst">&#123;c&#125;</span>, c.shape: <span class="subst">&#123;c.shape&#125;</span>&#x27;</span>)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a: [[1 2]</span><br><span class="line"> [3 4]</span><br><span class="line"> [5 6]], a.shape: (3, 2)</span><br><span class="line">b: [1 2 3 4 5 6], b.shape: (6,)</span><br><span class="line">c: [[1 2 3]</span><br><span class="line"> [4 5 6]], c.shape: (2, 3)</span><br></pre></td></tr></table></figure><h2 id="브로드캐스팅"><a href="#브로드캐스팅" class="headerlink" title="브로드캐스팅"></a>브로드캐스팅</h2><hr><p>브로드캐스팅은 numpy에서 도입된 개념으로 행렬과 서로 다른 크기의 벡터를 더할 때 쓰인다.</p><p>본래 선형대수에서 정의되지 않지만 벡터를 브로드캐스트(확산)하여 계산할 수 있는 형태로 만든 것이다.</p><img src="https://i.ibb.co/5YZ6Gsk/2022-03-03-1-37-24.png" alt="https://i.ibb.co/5YZ6Gsk/2022-03-03-1-37-24.png" width="500" /><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.ones((<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;a&#x27;</span>, a)</span><br><span class="line"></span><br><span class="line">b = tf.ones(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;b&#x27;</span>, b)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;a+b&#x27;</span>, a + b)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">a tf.Tensor(</span><br><span class="line">[[1. 1.]</span><br><span class="line"> [1. 1.]], shape=(2, 2), dtype=float32)</span><br><span class="line">b tf.Tensor([1.], shape=(1,), dtype=float32)</span><br><span class="line">a+b tf.Tensor(</span><br><span class="line">[[2. 2.]</span><br><span class="line"> [2. 2.]], shape=(2, 2), dtype=float32)</span><br></pre></td></tr></table></figure><h2 id="텐서-변수"><a href="#텐서-변수" class="headerlink" title="텐서 변수"></a>텐서 변수</h2><hr><p><code>tf.Variable</code> 객체는 <code>tf.Tensor</code>를 담고있는 변수 역할을 하는 객체이다.</p><p><code>.assign()</code> 함수를 통해 다른 <code>tf.Tensor</code>로 배정할 수 있다.</p><blockquote><p>공학적인 측면에서 생각해보자.</p><p>a = a = tf.Variable(tf.constant([1., 2.]))의 경우 레퍼런스 구조가 a -&gt; tf.Variable -&gt; tf.Tensor 된다.</p><p>tf.Variable이 변수 처럼 동작하는 이유는 tf.Variable의 레퍼런스를 교체할 수 있기 때문이다.</p></blockquote><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.constant([<span class="number">1.</span>, <span class="number">2.</span>])</span><br><span class="line">v_a = tf.Variable(a)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(v_a)</span><br><span class="line"></span><br><span class="line">v_a.assign([<span class="number">3.</span>, <span class="number">4.</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(v_a)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;tf.Variable &#x27;Variable:0&#x27; shape=(2,) dtype=float32, numpy=array([1., 2.], dtype=float32)&gt;</span><br><span class="line">&lt;tf.Variable &#x27;Variable:0&#x27; shape=(2,) dtype=float32, numpy=array([3., 4.], dtype=float32)&gt;</span><br></pre></td></tr></table></figure><p>머신 러닝에서 업데이트 되는 가중치를 표현할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">w_init = tf.transpose(tf.constant([[<span class="number">1.</span>, <span class="number">2.</span>]]))</span><br><span class="line">W = tf.Variable(w_init)</span><br><span class="line">x = tf.constant([[<span class="number">2.</span>, <span class="number">3.</span>]])</span><br><span class="line"></span><br><span class="line">y = tf.linalg.matmul(x, W)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y)</span><br><span class="line"></span><br><span class="line">w_add = tf.constant([<span class="number">1.</span>])</span><br><span class="line">W.assign(W + w_add) <span class="comment"># 각 가중치 값에 +1</span></span><br><span class="line"></span><br><span class="line">y = tf.linalg.matmul(x, W)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y)</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tf.Tensor([[8.]], shape=(1, 1), dtype=float32)</span><br><span class="line">tf.Tensor([[13.]], shape=(1, 1), dtype=float32)</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://jehwanyoo.net/categories/AI/">AI</category>
      
      
      <category domain="https://jehwanyoo.net/tags/Machine-Learning/">Machine Learning</category>
      
      <category domain="https://jehwanyoo.net/tags/AI/">AI</category>
      
      <category domain="https://jehwanyoo.net/tags/Deep-Learning/">Deep Learning</category>
      
      
      <comments>https://jehwanyoo.net/2022/03/06/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D%EC%9D%84-%ED%95%B4%EB%B3%B4%EC%9E%90-6%EC%9E%A5-%ED%85%90%EC%84%9C%ED%94%8C%EB%A1%9C%EC%9A%B0-%EA%B8%B0%EC%B4%88/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>배열 90도 회전 알고리즘 (시계, 반시계)</title>
      <link>https://jehwanyoo.net/2022/03/04/%EB%B0%B0%EC%97%B4-90%EB%8F%84-%ED%9A%8C%EC%A0%84-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%8B%9C%EA%B3%84-%EB%B0%98%EC%8B%9C%EA%B3%84/</link>
      <guid>https://jehwanyoo.net/2022/03/04/%EB%B0%B0%EC%97%B4-90%EB%8F%84-%ED%9A%8C%EC%A0%84-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%8B%9C%EA%B3%84-%EB%B0%98%EC%8B%9C%EA%B3%84/</guid>
      <pubDate>Fri, 04 Mar 2022 08:24:24 GMT</pubDate>
      
        
        
      <description>&lt;figure class=&quot;highlight python&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span clas</description>
        
      
      
      
      <content:encoded><![CDATA[<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_matrix_90</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    시계 방향으로 회전</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    m = <span class="built_in">len</span>(a[<span class="number">0</span>])</span><br><span class="line">    result = [[<span class="number">0</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            result[j][n-i-<span class="number">1</span>] = a[i][j]</span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">rotate_matrix_90_r</span>(<span class="params">a</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    반시계 방향으로 회전</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    n = <span class="built_in">len</span>(a)</span><br><span class="line">    m = <span class="built_in">len</span>(a[<span class="number">0</span>])</span><br><span class="line">    result = [[<span class="number">0</span>] * n <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(m)]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            result[n-j-<span class="number">1</span>][i] = a[i][j]</span><br><span class="line">    <span class="keyword">return</span> result</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://jehwanyoo.net/categories/Algorithms/">Algorithms</category>
      
      
      <category domain="https://jehwanyoo.net/tags/Algorithms/">Algorithms</category>
      
      <category domain="https://jehwanyoo.net/tags/ASeries/">ASeries</category>
      
      <category domain="https://jehwanyoo.net/tags/Rotate/">Rotate</category>
      
      
      <comments>https://jehwanyoo.net/2022/03/04/%EB%B0%B0%EC%97%B4-90%EB%8F%84-%ED%9A%8C%EC%A0%84-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98-%EC%8B%9C%EA%B3%84-%EB%B0%98%EC%8B%9C%EA%B3%84/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>선형(linear)이란 무엇인가?</title>
      <link>https://jehwanyoo.net/2022/03/03/%EC%84%A0%ED%98%95-linear-%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80/</link>
      <guid>https://jehwanyoo.net/2022/03/03/%EC%84%A0%ED%98%95-linear-%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80/</guid>
      <pubDate>Thu, 03 Mar 2022 06:46:44 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;선형-Linear-에-관하여&quot;&gt;&lt;a href=&quot;#선형-Linear-에-관하여&quot; class=&quot;headerlink&quot; title=&quot;선형(Linear)에 관하여&quot;&gt;&lt;/a&gt;선형(Linear)에 관하여&lt;/h2&gt;&lt;hr&gt;
&lt;p&gt;머신 러닝을 공부하다보면</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="선형-Linear-에-관하여"><a href="#선형-Linear-에-관하여" class="headerlink" title="선형(Linear)에 관하여"></a>선형(Linear)에 관하여</h2><hr><p>머신 러닝을 공부하다보면 ‘선형’이라는 말을 자주 접하게 된다.</p><p>하지만 ‘선형’이라는 용어가 상당히 혼용되어 사용되고 있다.</p><p>이번 기회에 ‘선형’이 무엇인지 확실히 집고 넘어가자.</p><h2 id="선형-함수-Linear-Function-의-두가지-정의"><a href="#선형-함수-Linear-Function-의-두가지-정의" class="headerlink" title="선형 함수(Linear Function)의 두가지 정의"></a>선형 함수(Linear Function)의 두가지 정의</h2><hr><h3 id="미적분학-Calculus-에서-선형-함수-다항식-함수-관점"><a href="#미적분학-Calculus-에서-선형-함수-다항식-함수-관점" class="headerlink" title="미적분학(Calculus)에서 선형 함수 (다항식 함수 관점)"></a>미적분학(Calculus)에서 선형 함수 (다항식 함수 관점)</h3><p>$y=ax+b$ 형태의 직선의 방정식으로 나타낼 수 있는 함수.</p><p>$deg(y) = 0$ (상수 함수)또는 $deg(y)=1$ (1차 함수)인 함수이다.</p><p>다항식 함수(Polynomial Function) 관점에서 선형 함수는 ‘직선’ 형태를 가지고 있다.</p><h3 id="선형대수학-Linear-Algebra-에서-선형-함수-선형-사상-관점"><a href="#선형대수학-Linear-Algebra-에서-선형-함수-선형-사상-관점" class="headerlink" title="선형대수학(Linear Algebra)에서 선형 함수 (선형 사상 관점)"></a>선형대수학(Linear Algebra)에서 선형 함수 (선형 사상 관점)</h3><p>$f(x+y) = f(x) + f(y)$ (가산성)</p><p>$f(cx) = cf(x)$ (동차성)</p><p>즉, 선형성(linearity)을 만족하는 함수.</p><p>만약, $y=ax+b$ 꼴이라면 $(b=0)$ 일 때만 선형 함수이다. (원점을 지나는 직선)</p><p>원점을 지나지 않는 경우$(b \neq 0)$를 구분하여 Affine Function(아핀 함수)라고 한다.</p><h2 id="선형-함수-개념의-충돌"><a href="#선형-함수-개념의-충돌" class="headerlink" title="선형 함수 개념의 충돌"></a>선형 함수 개념의 충돌</h2><hr><p>어떤 관점에서 생각하느냐에 따라 다르게 정의 될 수 있다.</p><p>우리가 일반적으로 말하는 ‘선형’은 다항식 함수에서의 선형으로 ‘직선’과 같은 말이다.</p><p>그러나 ‘선형 사상(Linear Map)’을 다루는 선형대수학에서는</p><p>우리가 선형 함수라고 불러왔던, 원점을 지나지 않는 1차 함수는 더이상 선형 함수가 아니다.</p><p>$f(x)=x+1$이라는 함수를 생각해보자.</p><p>선형성을 만족한다면, $f(3) = f(1) + f(2)$를 만족해야한다.</p><p>$f(3) = 4$이고</p><p>$f(1) = 2, f(2) = 3$</p><p>$f(1)+f(2) = 5$</p><p>이기 때문에 $f(x) = x+1$은 선형 함수가 될 수 없다.</p><h2 id="선형-회귀와-선형-모델"><a href="#선형-회귀와-선형-모델" class="headerlink" title="선형 회귀와 선형 모델"></a>선형 회귀와 선형 모델</h2><hr><p>‘선형 회귀’는 ($\beta_0 + \beta_1x_1 + \beta_1x_2 + …$) 꼴의 선형 형식(linear form)을 이용하여 변수간의 관계를 보여준다.</p><p>‘선형 모델’이라는 것은 어떤 관계가 ‘선형 형식’에 가깝게 표현될 수 있다는 것을 의미한다.</p><p>그런데 선형대수학 측면에서 보자면 선형 회귀는 ‘비선형 함수’를 사용하고 있다.</p><p>선형성(Linearity) 정의에 의하여 선형 모델은 선형 함수가 아닌 ‘아핀 함수’이기 때문이다.</p><h2 id="결론"><a href="#결론" class="headerlink" title="결론"></a>결론</h2><hr><p>미적분학에서는 ‘선형 형식(linear form)’을 만족하는 함수를 선형 함수라고 부른다.</p><p>선형대수학에서는 사상(map)의 결과가 ‘선형성(liniearity)’을 유지할 때 선형 함수라고 부른다.</p><p>결론적으로 선형 회귀는 회귀식 자체가 선형성을 가졌다는게 아닌 <strong>‘선형 모델’을 이용한 통계적 방법</strong>을 의미한다는 것을 알 수 있다.</p><h2 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h2><hr><ul><li><a href="https://en.wikipedia.org/wiki/Linear_function">Linear Function</a></li><li><a href="https://towardsdatascience.com/is-a-straight-line-linear-f9f491514e97">Is a straight line linear?</a></li><li><a href="https://hooni-playground.com/1271/">선형변환과 아핀변환에 대한 고찰</a></li></ul>]]></content:encoded>
      
      
      <category domain="https://jehwanyoo.net/categories/Mathematics/">Mathematics</category>
      
      
      <category domain="https://jehwanyoo.net/tags/Mathematics/">Mathematics</category>
      
      <category domain="https://jehwanyoo.net/tags/Calculus/">Calculus</category>
      
      <category domain="https://jehwanyoo.net/tags/Linear-Algebra/">Linear Algebra</category>
      
      <category domain="https://jehwanyoo.net/tags/Linear-Function/">Linear Function</category>
      
      <category domain="https://jehwanyoo.net/tags/Linear-Regression/">Linear Regression</category>
      
      <category domain="https://jehwanyoo.net/tags/Affine-Function/">Affine Function</category>
      
      
      <comments>https://jehwanyoo.net/2022/03/03/%EC%84%A0%ED%98%95-linear-%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>(이진 탐색) Count By Range 알고리즘</title>
      <link>https://jehwanyoo.net/2022/03/02/%EC%9D%B4%EC%A7%84-%ED%83%90%EC%83%89-Count-By-Range-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/</link>
      <guid>https://jehwanyoo.net/2022/03/02/%EC%9D%B4%EC%A7%84-%ED%83%90%EC%83%89-Count-By-Range-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/</guid>
      <pubDate>Wed, 02 Mar 2022 11:22:25 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;분류&quot;&gt;&lt;a href=&quot;#분류&quot; class=&quot;headerlink&quot; title=&quot;분류&quot;&gt;&lt;/a&gt;분류&lt;/h2&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;이진 탐색&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;알고리즘-코드&quot;&gt;&lt;a href=&quot;#알고리즘-코드&quot; class=</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="분류"><a href="#분류" class="headerlink" title="분류"></a>분류</h2><hr><ul><li>이진 탐색</li></ul><h2 id="알고리즘-코드"><a href="#알고리즘-코드" class="headerlink" title="알고리즘 코드"></a>알고리즘 코드</h2><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bisect <span class="keyword">import</span> bisect_left, bisect_right</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_by_range</span>(<span class="params">a, left_value, right_value</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    list a에서 left_value &lt;= x &lt;= right_value인 원소를 찾는 알고리즘</span></span><br><span class="line"><span class="string">    O(logN)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    right_index = bisect_right(a, right_value)</span><br><span class="line">    left_index = bisect_left(a, left_value)</span><br><span class="line">    <span class="keyword">return</span> right_index - left_index</span><br></pre></td></tr></table></figure><blockquote><p>bisect: 정렬을 깨지 않는 선에서 해당 원소를 삽입할 수 있는 위치를 찾는 이진 탐색 함수</p></blockquote><h2 id="관련-문제"><a href="#관련-문제" class="headerlink" title="관련 문제"></a>관련 문제</h2><hr><h3 id="2020-KAKAO-BLIND-RECRUITMENT-가사-검색"><a href="#2020-KAKAO-BLIND-RECRUITMENT-가사-검색" class="headerlink" title="2020 KAKAO BLIND RECRUITMENT - 가사 검색"></a>2020 KAKAO BLIND RECRUITMENT - 가사 검색</h3><p><a href="https://programmers.co.kr/learn/courses/30/lessons/60060">https://programmers.co.kr/learn/courses/30/lessons/60060</a></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> bisect <span class="keyword">import</span> bisect_left, bisect_right</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">count_by_range</span>(<span class="params">a, left_value, right_value</span>):</span></span><br><span class="line">    right_index = bisect_right(a, right_value)</span><br><span class="line">    left_index = bisect_left(a, left_value)</span><br><span class="line">    <span class="keyword">return</span> right_index - left_index</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">solution</span>(<span class="params">words, queries</span>):</span></span><br><span class="line">    array = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    reversed_array = defaultdict(<span class="built_in">list</span>)</span><br><span class="line">    answer = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">        array[<span class="built_in">len</span>(word)].append(word)</span><br><span class="line">        reversed_array[<span class="built_in">len</span>(word)].append(word[::-<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> array.keys():</span><br><span class="line">        array[k].sort()</span><br><span class="line">        reversed_array[k].sort()</span><br><span class="line">                </span><br><span class="line">    <span class="keyword">for</span> q <span class="keyword">in</span> queries:</span><br><span class="line">        <span class="keyword">if</span> q[<span class="number">0</span>] != <span class="string">&#x27;?&#x27;</span>:</span><br><span class="line">            res = count_by_range(array[<span class="built_in">len</span>(q)], q.replace(<span class="string">&#x27;?&#x27;</span>, <span class="string">&#x27;a&#x27;</span>), q.replace(<span class="string">&#x27;?&#x27;</span>, <span class="string">&#x27;z&#x27;</span>))</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            res = count_by_range(reversed_array[<span class="built_in">len</span>(q)], q[::-<span class="number">1</span>].replace(<span class="string">&#x27;?&#x27;</span>, <span class="string">&#x27;a&#x27;</span>), q[::-<span class="number">1</span>].replace(<span class="string">&#x27;?&#x27;</span>, <span class="string">&#x27;z&#x27;</span>))</span><br><span class="line">        answer.append(res)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> answer</span><br></pre></td></tr></table></figure><p>예를들어 fro??를 찾는다면 froaa ~ frozz 사이에 있는 원소의 개수를 찾는다. (정렬이 되어있으므로 가능)</p><p>만약 와일드카드가 앞에 존재한다면 문자를 뒤집어서 생각한다.</p><h2 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h2><hr><p><strong><a href="http://www.yes24.com/Product/Goods/91433923">이것이 취업을 위한 코딩 테스트다 with 파이썬 (2021)</a></strong></p>]]></content:encoded>
      
      
      <category domain="https://jehwanyoo.net/categories/Algorithms/">Algorithms</category>
      
      
      <category domain="https://jehwanyoo.net/tags/Algorithms/">Algorithms</category>
      
      <category domain="https://jehwanyoo.net/tags/ASeries/">ASeries</category>
      
      <category domain="https://jehwanyoo.net/tags/Binary-Search/">Binary Search</category>
      
      <category domain="https://jehwanyoo.net/tags/Bisect/">Bisect</category>
      
      
      <comments>https://jehwanyoo.net/2022/03/02/%EC%9D%B4%EC%A7%84-%ED%83%90%EC%83%89-Count-By-Range-%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>비트 마스크(Bit Mask)</title>
      <link>https://jehwanyoo.net/2022/02/28/%EB%B9%84%ED%8A%B8-%EB%A7%88%EC%8A%A4%ED%81%AC-Bit-Mask/</link>
      <guid>https://jehwanyoo.net/2022/02/28/%EB%B9%84%ED%8A%B8-%EB%A7%88%EC%8A%A4%ED%81%AC-Bit-Mask/</guid>
      <pubDate>Mon, 28 Feb 2022 09:14:21 GMT</pubDate>
      
        
        
      <description>&lt;h2 id=&quot;분류&quot;&gt;&lt;a href=&quot;#분류&quot; class=&quot;headerlink&quot; title=&quot;분류&quot;&gt;&lt;/a&gt;분류&lt;/h2&gt;&lt;hr&gt;
&lt;ul&gt;
&lt;li&gt;비트 마스크 알고리즘&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;설명&quot;&gt;&lt;a href=&quot;#설명&quot; class=&quot;hea</description>
        
      
      
      
      <content:encoded><![CDATA[<h2 id="분류"><a href="#분류" class="headerlink" title="분류"></a>분류</h2><hr><ul><li>비트 마스크 알고리즘</li></ul><h2 id="설명"><a href="#설명" class="headerlink" title="설명"></a>설명</h2><hr><p>어떤 상태를 나타내기 위해 배열을 사용하는 것이 아닌 2의 보수 체계를 이용하여 계산하는 방법</p><p>컴퓨터 엔지니어링 측면에서 굉장히 빠른 방법이라고 할 수 있다.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">show</span>(<span class="params">a</span>):</span></span><br><span class="line">    b = [<span class="number">0</span>] * <span class="number">32</span></span><br><span class="line">    i = <span class="number">32</span></span><br><span class="line">    <span class="keyword">while</span> i &gt; <span class="number">0</span>:</span><br><span class="line">        b[<span class="number">32</span>-i] = <span class="number">1</span> <span class="keyword">if</span> a &amp; (<span class="number">1</span> &lt;&lt; (i-<span class="number">1</span>)) <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">        i -= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> b </span><br><span class="line"></span><br><span class="line">show(a) <span class="comment"># 선택된 원소 보기 (32 bit - int)</span></span><br><span class="line">a = <span class="number">0</span> <span class="comment"># 원소 초기화 (0・・・0000)</span></span><br><span class="line">a = -<span class="number">1</span> <span class="comment"># 모든 원소 선택 (1・・・1111)</span></span><br><span class="line">a &amp;= ~(<span class="number">1</span>&lt;&lt;i) <span class="comment"># 2^i 위치 원소 삭제</span></span><br><span class="line">a |= (<span class="number">1</span>&lt;&lt;i) <span class="comment"># 2^i 위치 원소 선택</span></span><br><span class="line">a &amp; (<span class="number">1</span>&lt;&lt;i) <span class="comment"># 2^i 번째가 선택되었는가?</span></span><br><span class="line">a ^= (<span class="number">1</span>&lt;&lt;i) <span class="comment"># 2^i 번째 원소 토글</span></span><br><span class="line">(a &amp; -a) <span class="comment"># 0이 아닌 마지막 비트 구하기</span></span><br><span class="line">a &amp;= (a - <span class="number">1</span>) <span class="comment"># 마지막 원소 삭제</span></span><br></pre></td></tr></table></figure><h2 id="참고"><a href="#참고" class="headerlink" title="참고"></a>참고</h2><hr><p><a href="https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&blogId=ndb796&logNo=221312837477">https://m.blog.naver.com/PostView.naver?isHttpsRedirect=true&amp;blogId=ndb796&amp;logNo=221312837477</a></p>]]></content:encoded>
      
      
      <category domain="https://jehwanyoo.net/categories/Algorithms/">Algorithms</category>
      
      
      <category domain="https://jehwanyoo.net/tags/Algorithms/">Algorithms</category>
      
      <category domain="https://jehwanyoo.net/tags/ASeries/">ASeries</category>
      
      <category domain="https://jehwanyoo.net/tags/Bit-Mask/">Bit Mask</category>
      
      
      <comments>https://jehwanyoo.net/2022/02/28/%EB%B9%84%ED%8A%B8-%EB%A7%88%EC%8A%A4%ED%81%AC-Bit-Mask/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
